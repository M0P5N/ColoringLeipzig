{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeviceId.GPU0: 0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:  This must be the first call in order to work properly!\n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "#choices:  CPU, GPU0...GPU7\n",
    "device.set(device=DeviceId.GPU0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deoldify.visualize import *\n",
    "plt.style.use('dark_background')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:  Set artistic to False if you're having trouble getting a good render.  Chances are it will work with the Stable model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\ColorizeArtistic_gen.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m colorizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_image_colorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43martistic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Dropbox\\PC\\Desktop\\deoldify\\DeOldify\\deoldify\\visualize.py:442\u001b[0m, in \u001b[0;36mget_image_colorizer\u001b[1;34m(root_folder, render_factor, artistic)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_colorizer\u001b[39m(\n\u001b[0;32m    439\u001b[0m     root_folder: Path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m), render_factor: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m, artistic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelImageVisualizer:\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artistic:\n\u001b[1;32m--> 442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artistic_image_colorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_stable_image_colorizer(root_folder\u001b[38;5;241m=\u001b[39mroot_folder, render_factor\u001b[38;5;241m=\u001b[39mrender_factor)\n",
      "File \u001b[1;32m~\\Dropbox\\PC\\Desktop\\deoldify\\DeOldify\\deoldify\\visualize.py:465\u001b[0m, in \u001b[0;36mget_artistic_image_colorizer\u001b[1;34m(root_folder, weights_name, results_dir, render_factor)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artistic_image_colorizer\u001b[39m(\n\u001b[0;32m    460\u001b[0m     root_folder: Path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    461\u001b[0m     weights_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColorizeArtistic_gen\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    462\u001b[0m     results_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_images\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    463\u001b[0m     render_factor: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m    464\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelImageVisualizer:\n\u001b[1;32m--> 465\u001b[0m     learn \u001b[38;5;241m=\u001b[39m \u001b[43mgen_inference_deep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m     filtr \u001b[38;5;241m=\u001b[39m MasterFilter([ColorizerFilter(learn\u001b[38;5;241m=\u001b[39mlearn)], render_factor\u001b[38;5;241m=\u001b[39mrender_factor)\n\u001b[0;32m    467\u001b[0m     vis \u001b[38;5;241m=\u001b[39m ModelImageVisualizer(filtr, results_dir\u001b[38;5;241m=\u001b[39mresults_dir)\n",
      "File \u001b[1;32m~\\Dropbox\\PC\\Desktop\\deoldify\\DeOldify\\deoldify\\generators.py:92\u001b[0m, in \u001b[0;36mgen_inference_deep\u001b[1;34m(root_folder, weights_name, arch, nf_factor)\u001b[0m\n\u001b[0;32m     88\u001b[0m learn \u001b[38;5;241m=\u001b[39m gen_learner_deep(\n\u001b[0;32m     89\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata, gen_loss\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39ml1_loss, arch\u001b[38;5;241m=\u001b[39march, nf_factor\u001b[38;5;241m=\u001b[39mnf_factor\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m learn\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m root_folder\n\u001b[1;32m---> 92\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m learn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "File \u001b[1;32m~\\Dropbox\\PC\\Desktop\\deoldify\\DeOldify\\fastai\\basic_train.py:271\u001b[0m, in \u001b[0;36mLearner.load\u001b[1;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m): device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[0;32m    270\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 271\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(state\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[0;32m    273\u001b[0m     model_state \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deoldify\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deoldify\\lib\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deoldify\\lib\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models\\\\ColorizeArtistic_gen.pth'"
     ]
    }
   ],
   "source": [
    "colorizer = get_image_colorizer(artistic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "### source_url\n",
    "Type in a url to a direct link of an image.  Usually that means they'll end in .png, .jpg, etc.  NOTE: If you want to use your own image, you can set source_url to None and just upload the image to /test_images/ in Jupyter.  Just make sure that the source_path parameter matches the file you uploaded.\n",
    "\n",
    "### source_path\n",
    "Name this whatever sensible image path (plus extension of jpg/png/ext) you want!  Sensible means the path exists and the file exists if source_url=None.\n",
    "\n",
    "### render_factor\n",
    "The default value of 35 has been carefully chosen and should work -ok- for most scenarios (but probably won't be the -best-). This determines resolution at which the color portion of the image is rendered. Lower resolution will render faster, and colors also tend to look more vibrant. Older and lower quality images in particular will generally benefit by lowering the render factor. Higher render factors are often better for higher quality images, but the colors may get slightly washed out. \n",
    "\n",
    "### result_path\n",
    "Ditto- don't change.\n",
    "\n",
    "### How to Download a Copy\n",
    "Simply shift+right click on the displayed image and click \"Save Image As...\"!\n",
    "\n",
    "\n",
    "## Pro Tips\n",
    "1. You can evaluate how well the image is rendered at each render_factor by using the code at the bottom (that cell under \"See how well render_factor values perform on a frame here\"). \n",
    "2. Keep in mind again that you can go up top and set artistic to False for the colorizer to use the 'Stable' model instead.  This will often tend to do better on portraits, and natural landscapes.  \n",
    "\n",
    "\n",
    "## Troubleshooting\n",
    "If you get a 'CUDA out of memory' error, you probably have the render_factor too high.  The max is 45 on 11GB video cards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorize!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE:  Max is 45 with 11GB video cards. 35 is a good default\n",
    "render_factor=35\n",
    "#NOTE:  Make source_url None to just read from file at ./video/source/[file_name] directly without modification\n",
    "source_url='https://upload.wikimedia.org/wikipedia/commons/e/e4/Raceland_Louisiana_Beer_Drinkers_Russell_Lee.jpg'\n",
    "source_path = 'test_images/mendebrunnen karl-marx-platz1988.jpg'\n",
    "result_path = None\n",
    "\n",
    "if source_url is not None:\n",
    "    result_path = colorizer.plot_transformed_image_from_url(url=source_url, path=source_path, render_factor=render_factor, compare=True)\n",
    "else:\n",
    "    result_path = colorizer.plot_transformed_image(path=source_path, render_factor=render_factor, compare=True)\n",
    "\n",
    "show_image_in_notebook(result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how well render_factor values perform on the image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12,40):\n",
    "    #colorizer.plot_transformed_image(source_path, render_factor=i, display_render_factor=True, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
